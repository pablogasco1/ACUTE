{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.tools.geomap_tools import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = \"data/external/adsb/\"\n",
    "year_selected = \"2024\"\n",
    "sites = pd.read_csv(\"data/external/sites.csv\")\n",
    "sites.loc[sites.name==\"EIH\", \"name\"] = \"BRE\"\n",
    "sites.rename(columns={\"id\" : \"site_id\", \"name\" : \"site_abrev_name\", \"basename\" : \"site_name\", \"code\" : \"site_code\"}, inplace=True)\n",
    "time_threshold = pd.Timedelta(minutes=20)\n",
    "maximum_altitude = 8000 # feet\n",
    "maximum_distance = 20 # km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London_2024-07-01.parquet\n",
      "London_2024-07-02.parquet\n",
      "London_2024-07-03.parquet\n",
      "London_2024-07-04.parquet\n",
      "London_2024-07-05.parquet\n",
      "London_2024-07-06.parquet\n",
      "London_2024-07-07.parquet\n",
      "London_2024-07-08.parquet\n",
      "London_2024-07-09.parquet\n",
      "London_2024-07-10.parquet\n",
      "London_2024-07-11.parquet\n",
      "London_2024-07-12.parquet\n",
      "London_2024-07-13.parquet\n",
      "London_2024-07-14.parquet\n",
      "London_2024-07-15.parquet\n",
      "London_2024-07-16.parquet\n",
      "London_2024-07-17.parquet\n",
      "London_2024-07-18.parquet\n",
      "London_2024-07-19.parquet\n",
      "London_2024-07-20.parquet\n",
      "London_2024-07-21.parquet\n",
      "London_2024-07-22.parquet\n",
      "London_2024-07-23.parquet\n",
      "London_2024-07-24.parquet\n",
      "London_2024-07-25.parquet\n",
      "London_2024-07-26.parquet\n",
      "London_2024-07-27.parquet\n",
      "London_2024-07-28.parquet\n",
      "London_2024-07-29.parquet\n",
      "London_2024-07-30.parquet\n",
      "London_2024-07-31.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-08-01.parquet\n",
      "London_2024-08-02.parquet\n",
      "London_2024-08-03.parquet\n",
      "London_2024-08-04.parquet\n",
      "London_2024-08-05.parquet\n",
      "London_2024-08-06.parquet\n",
      "London_2024-08-07.parquet\n",
      "London_2024-08-08.parquet\n",
      "London_2024-08-09.parquet\n",
      "London_2024-08-10.parquet\n",
      "London_2024-08-11.parquet\n",
      "London_2024-08-12.parquet\n",
      "London_2024-08-13.parquet\n",
      "London_2024-08-14.parquet\n",
      "London_2024-08-15.parquet\n",
      "London_2024-08-16.parquet\n",
      "London_2024-08-17.parquet\n",
      "London_2024-08-18.parquet\n",
      "London_2024-08-19.parquet\n",
      "London_2024-08-20.parquet\n",
      "London_2024-08-21.parquet\n",
      "London_2024-08-22.parquet\n",
      "London_2024-08-23.parquet\n",
      "London_2024-08-24.parquet\n",
      "London_2024-08-25.parquet\n",
      "London_2024-08-26.parquet\n",
      "London_2024-08-27.parquet\n",
      "London_2024-08-28.parquet\n",
      "London_2024-08-29.parquet\n",
      "London_2024-08-30.parquet\n",
      "London_2024-08-31.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-09-01.parquet\n",
      "London_2024-09-02.parquet\n",
      "London_2024-09-03.parquet\n",
      "London_2024-09-04.parquet\n",
      "London_2024-09-05.parquet\n",
      "London_2024-09-06.parquet\n",
      "London_2024-09-07.parquet\n",
      "London_2024-09-08.parquet\n",
      "London_2024-09-09.parquet\n",
      "London_2024-09-10.parquet\n",
      "London_2024-09-11.parquet\n",
      "London_2024-09-12.parquet\n",
      "London_2024-09-13.parquet\n",
      "London_2024-09-14.parquet\n",
      "London_2024-09-15.parquet\n",
      "London_2024-09-16.parquet\n",
      "London_2024-09-17.parquet\n",
      "London_2024-09-18.parquet\n",
      "London_2024-09-19.parquet\n",
      "London_2024-09-20.parquet\n",
      "London_2024-09-21.parquet\n",
      "London_2024-09-22.parquet\n",
      "London_2024-09-23.parquet\n",
      "London_2024-09-24.parquet\n",
      "London_2024-09-25.parquet\n",
      "London_2024-09-26.parquet\n",
      "London_2024-09-27.parquet\n",
      "London_2024-09-28.parquet\n",
      "London_2024-09-29.parquet\n",
      "London_2024-09-30.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-10-01.parquet\n",
      "London_2024-10-02.parquet\n",
      "London_2024-10-03.parquet\n",
      "London_2024-10-04.parquet\n",
      "London_2024-10-05.parquet\n",
      "London_2024-10-06.parquet\n",
      "London_2024-10-07.parquet\n",
      "London_2024-10-08.parquet\n",
      "London_2024-10-09.parquet\n",
      "London_2024-10-10.parquet\n",
      "London_2024-10-11.parquet\n",
      "London_2024-10-12.parquet\n",
      "London_2024-10-13.parquet\n",
      "London_2024-10-14.parquet\n",
      "London_2024-10-15.parquet\n",
      "London_2024-10-16.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-01-02.parquet\n",
      "London_2024-01-03.parquet\n",
      "London_2024-01-04.parquet\n",
      "London_2024-01-05.parquet\n",
      "London_2024-01-06.parquet\n",
      "London_2024-01-08.parquet\n",
      "London_2024-01-09.parquet\n",
      "London_2024-01-12.parquet\n",
      "London_2024-01-13.parquet\n",
      "London_2024-01-14.parquet\n",
      "London_2024-01-15.parquet\n",
      "London_2024-01-16.parquet\n",
      "London_2024-01-17.parquet\n",
      "London_2024-01-18.parquet\n",
      "London_2024-01-20.parquet\n",
      "London_2024-01-21.parquet\n",
      "London_2024-01-22.parquet\n",
      "London_2024-01-23.parquet\n",
      "London_2024-01-24.parquet\n",
      "London_2024-01-25.parquet\n",
      "London_2024-01-26.parquet\n",
      "London_2024-01-27.parquet\n",
      "London_2024-01-28.parquet\n",
      "London_2024-01-30.parquet\n",
      "London_2024-01-31.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "Gatwick_2024-02-27.parquet\n",
      "Gatwick_2024-02-27.parquet has TypeError\n",
      "Gatwick_2024-02-28.parquet\n",
      "Gatwick_2024-02-28.parquet has TypeError\n",
      "London_2024-02-01.parquet\n",
      "London_2024-02-02.parquet\n",
      "London_2024-02-03.parquet\n",
      "London_2024-02-06.parquet\n",
      "London_2024-02-06.parquet has TypeError\n",
      "London_2024-02-07.parquet\n",
      "London_2024-02-07.parquet has TypeError\n",
      "London_2024-02-08.parquet\n",
      "London_2024-02-08.parquet has TypeError\n",
      "London_2024-02-09.parquet\n",
      "London_2024-02-09.parquet has TypeError\n",
      "London_2024-02-10.parquet\n",
      "London_2024-02-10.parquet has TypeError\n",
      "London_2024-02-11.parquet\n",
      "London_2024-02-11.parquet has TypeError\n",
      "London_2024-02-12.parquet\n",
      "London_2024-02-12.parquet has TypeError\n",
      "London_2024-02-13.parquet\n",
      "London_2024-02-13.parquet has TypeError\n",
      "London_2024-02-14.parquet\n",
      "London_2024-02-14.parquet has TypeError\n",
      "London_2024-02-15.parquet\n",
      "London_2024-02-15.parquet has TypeError\n",
      "London_2024-02-16.parquet\n",
      "London_2024-02-16.parquet has TypeError\n",
      "London_2024-02-17.parquet\n",
      "London_2024-02-17.parquet has TypeError\n",
      "London_2024-02-18.parquet\n",
      "London_2024-02-18.parquet has TypeError\n",
      "London_2024-02-19.parquet\n",
      "London_2024-02-19.parquet has TypeError\n",
      "London_2024-02-21.parquet\n",
      "London_2024-02-21.parquet has TypeError\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-03-26.parquet\n",
      "London_2024-03-27.parquet\n",
      "London_2024-03-28.parquet\n",
      "London_2024-03-29.parquet\n",
      "London_2024-03-30.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-04-02.parquet\n",
      "London_2024-04-03.parquet\n",
      "London_2024-04-04.parquet\n",
      "London_2024-04-05.parquet\n",
      "London_2024-04-06.parquet\n",
      "London_2024-04-07.parquet\n",
      "London_2024-04-08.parquet\n",
      "London_2024-04-09.parquet\n",
      "London_2024-04-10.parquet\n",
      "London_2024-04-11.parquet\n",
      "London_2024-04-12.parquet\n",
      "London_2024-04-13.parquet\n",
      "London_2024-04-14.parquet\n",
      "London_2024-04-15.parquet\n",
      "London_2024-04-16.parquet\n",
      "London_2024-04-17.parquet\n",
      "London_2024-04-18.parquet\n",
      "London_2024-04-19.parquet\n",
      "London_2024-04-20.parquet\n",
      "London_2024-04-21.parquet\n",
      "London_2024-04-22.parquet\n",
      "London_2024-04-23.parquet\n",
      "London_2024-04-24.parquet\n",
      "London_2024-04-25.parquet\n",
      "London_2024-04-26.parquet\n",
      "London_2024-04-27.parquet\n",
      "London_2024-04-28.parquet\n",
      "London_2024-04-30.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n",
      "London_2024-05-01.parquet\n",
      "London_2024-05-02.parquet\n",
      "London_2024-05-29.parquet\n",
      "London_2024-05-30.parquet\n",
      "London_2024-05-31.parquet\n",
      "concatening...\n",
      "sorting values...\n",
      "computing time diff...\n",
      "computing time flown...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Site\n",
       "LON   608 days 18:44:58.060000\n",
       "Name: timeFlown, dtype: timedelta64[ns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_table = []\n",
    "\n",
    "# Traverse through all folders and subfolders\n",
    "for root, dirs, files in os.walk(base_folder):\n",
    "    folder_dfs = []\n",
    "    # Iterate through files in the current folder\n",
    "    for file in files:\n",
    "\n",
    "        if file.endswith(\".parquet\"):\n",
    "            \n",
    "            # Extract site information from folder structure\n",
    "            site = re.search(r\"site=([^/]+)\", root).group(1)\n",
    "            year = re.search(r\"year=([^/]+)\", root).group(1)\n",
    "            month = re.search(r\"month=([^/]+)\", root).group(1)\n",
    "            \n",
    "            if site!=\"LON\":\n",
    "                 break\n",
    "            \n",
    "            if year!=year_selected:\n",
    "                break\n",
    "            \n",
    "            file_path = os.path.join(root, file)\n",
    "            # Read the parquet file into a pandas DataFrame\n",
    "            \n",
    "            try:\n",
    "                df = pd.read_parquet(file_path)\n",
    "            except OSError:\n",
    "                print(file + \" is corrupted\")\n",
    "                continue\n",
    "            \n",
    "            print(file)\n",
    "            \n",
    "            # Filter by geometric altitude\n",
    "            df = df[~df.GeometricAltitude.isnull()]\n",
    "            df.GeometricAltitude = df.GeometricAltitude.astype(float)\n",
    "            df = df[df.GeometricAltitude < maximum_altitude]\n",
    "            \n",
    "            df[\"Site\"] = site\n",
    "            df[\"Year\"] = year\n",
    "            df[\"Month\"] = month\n",
    "            \n",
    "            # Get site latitude and longitude from `sites` DataFrame\n",
    "            site_coords = sites[sites.site_abrev_name == site][[\"latitude\", \"longitude\"]].values[0]\n",
    "            site_lat, site_lon = site_coords\n",
    "            \n",
    "            try:\n",
    "                # Calculate distance and filter rows within 50km\n",
    "                df[\"Distance\"] = haversine(df[\"Latitude\"], df[\"Longitude\"], site_lat, site_lon)\n",
    "                df = df[df[\"Distance\"] <= maximum_distance]\n",
    "                \n",
    "                # Drop the temporary 'Distance' column\n",
    "                df.drop(columns=[\"Distance\"], inplace=True)\n",
    "            except TypeError:\n",
    "                print(file + \" has TypeError\")\n",
    "                continue\n",
    "            \n",
    "            if not df.empty:\n",
    "                folder_dfs.append(df)\n",
    "\n",
    "    if folder_dfs:\n",
    "        print(\"concatening...\")\n",
    "        # Combine DataFrames from the current folder (if needed)\n",
    "        df = pd.concat(folder_dfs, ignore_index=True)\n",
    "\n",
    "        # Sort the dataframe by AircraftAddress, Callsign, and TimeRecPosition\n",
    "        print(\"sorting values...\")\n",
    "        df.TimeRecPosition = pd.to_datetime(df.TimeRecPosition, format=\"ISO8601\")\n",
    "        df = df.sort_values(by=['AircraftAddress', 'Callsign', 'TimeRecPosition'])\n",
    "\n",
    "        # Calculate the time difference within each group\n",
    "        print(\"computing time diff...\")\n",
    "        df.loc[df.Callsign.isnull(), \"Callsign\"] = \"NONE\"\n",
    "        df['time_diff'] = df.groupby(['AircraftAddress', 'Callsign'])['TimeRecPosition'].diff()\n",
    "\n",
    "        # Initialize the journey column\n",
    "        df['journey'] = 0\n",
    "\n",
    "        # Create a flag for new journey based on time difference and new Callsign-AircraftAddress combination\n",
    "        df['new_journey'] = (df['time_diff'] > time_threshold) | (df['Callsign'] != df['Callsign'].shift(1)) | \\\n",
    "                            (df['Site'] != df['Site'].shift(1)) | (df['AircraftAddress'] != df['AircraftAddress'].shift(1))\n",
    "\n",
    "        # Use cumulative sum to assign journey IDs\n",
    "        df['journey'] = df['new_journey'].cumsum() + 1\n",
    "\n",
    "        # Calculate the time flown for each journey\n",
    "        print(\"computing time flown...\")\n",
    "        df['timeFlown'] = df.groupby('journey')['TimeRecPosition'].transform(lambda x: x.max() - x.min())\n",
    "        dfTime = df.drop_duplicates(subset=['journey']).reset_index(drop=True)\n",
    "        final_table.append(dfTime.groupby([\"Site\", \"Year\", \"Month\"])[\"timeFlown\"].sum().reset_index())\n",
    "        print(\"\")\n",
    "        \n",
    "final_table = [df for df in final_table if not df.empty]\n",
    "final_concat = pd.concat(final_table, ignore_index=True)\n",
    "final_by_site = pd.concat(final_table, ignore_index=True).groupby(\"Site\").timeFlown.sum()\n",
    "final_by_site\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EmitterCategory', 'GBS', 'ModeA', 'TimeRecPosition', 'AircraftAddress',\n",
       "       'Latitude', 'Longitude', 'GeometricAltitude', 'FlightLevel',\n",
       "       'BarometricVerticalRate', 'GeoVertRateExceeded',\n",
       "       'GeometricVerticalRate', 'GroundSpeed', 'TrackAngle', 'Callsign',\n",
       "       'AircraftStopped', 'GroundTrackValid', 'GroundHeadingProvided',\n",
       "       'MagneticNorth', 'SurfaceGroundSpeed', 'SurfaceGroundTrack', 'Site',\n",
       "       'Year', 'Month', 'time_diff', 'journey', 'new_journey', 'timeFlown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timeFlown</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Site</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUS</th>\n",
       "      <td>511 days 13:36:33.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRE</th>\n",
       "      <td>71 days 09:03:34.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BRU</th>\n",
       "      <td>33 days 15:56:38.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BUC</th>\n",
       "      <td>171 days 07:16:19.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CYP</th>\n",
       "      <td>97 days 02:41:29.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LON</th>\n",
       "      <td>608 days 18:44:58.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LUX</th>\n",
       "      <td>96 days 21:16:41.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PAP</th>\n",
       "      <td>30 days 23:08:20.620000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SAR</th>\n",
       "      <td>1 days 08:11:02.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZUR</th>\n",
       "      <td>247 days 12:40:55.660000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    timeFlown\n",
       "Site                         \n",
       "AUS  511 days 13:36:33.690000\n",
       "BRE   71 days 09:03:34.600000\n",
       "BRU   33 days 15:56:38.180000\n",
       "BUC  171 days 07:16:19.710000\n",
       "CYP   97 days 02:41:29.560000\n",
       "LON  608 days 18:44:58.060000\n",
       "LUX   96 days 21:16:41.450000\n",
       "PAP   30 days 23:08:20.620000\n",
       "SAR    1 days 08:11:02.950000\n",
       "ZUR  247 days 12:40:55.660000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(final_by_site)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acute",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
